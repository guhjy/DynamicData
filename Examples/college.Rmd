---
title: "College Scorecard"
date: "December 2017"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, fig.width = 6, fig.height = 4, fig.align = "center", cache=TRUE)
```

```{r echo=FALSE,message=FALSE, warning=FALSE}
require(tidyverse)
require(mosaic)
require(readr)
```


# Introduction

Data on characteristics of US institutions of higher education was collected in an effort to make more transparent issues of cost, debt, completion rates, and post-graduation earning potential.  An undertaking of the U.S. Department of Education, the College Scorecard data represent a compilation of institutional reporting, federal financial aid reports, and tax information.  The process of gathering and compiling the data is well documented on the College Scorecard website [https://collegescorecard.ed.gov/data/documentation/](https://collegescorecard.ed.gov/data/documentation/).  One caveat is that some of the variables have only been collected on students receiving federal financial aid.  Biases inherent to analyses done on data collected from a subgroup should be considered.


# Data information & loading data

There are multiple ways of downloading the College Scorecard data. The data are available: for all years (1996-2013) in a .zip file; as the most recent year (as this file is written, the most recent year is 2013) in a .csv file; or as the scorecard only data in a .csv file. [https://collegescorecard.ed.gov/data/](https://collegescorecard.ed.gov/data/).  For the analysis below, we have used the 2013 most recent data.  The original file contains 7804 institutions and 1728 variables.  

The dataset is incredibly rich.  The variables are broken down by race, family income, first generation status, age of student, etc.  It allows for a student to investigate political or personal hypotheses about college education and the costs and benefits within.  The variables are described in a data dictionary given at [https://collegescorecard.ed.gov/assets/CollegeScorecardDataDictionary-09-08-2015.csv](https://collegescorecard.ed.gov/assets/CollegeScorecardDataDictionary-09-08-2015.csv).


```{r}
college_url <- "https://s3.amazonaws.com/ed-college-choice-public/Most+Recent+Cohorts+(All+Data+Elements).csv"
college_data <- read_csv(college_url)
dim(college_data)
```

Let's only use some of the variables, and also let's make sure that they are all numeric with NA coded appropriately.

```{r}
college_debt = college_data %>% 
  dplyr::select(INSTNM,STABBR,PREDDEG, HIGHDEG, region, LOCALE,
         CCUGPROF,HBCU,WOMENONLY, RELAFFIL,ADM_RATE,SATVRMID,
         SATMTMID,SATWRMID,SAT_AVG, UG,NPT4_PUB, NPT4_PRIV,
         COSTT4_A, DEBT_MDN, CUML_DEBT_P90, mn_earn_wne_p10,
         md_earn_wne_p10) %>%
  mutate(ADM_RATE = readr::parse_number(ADM_RATE),
         SATVRMID = readr::parse_number(SATVRMID),
         SATMTMID = readr::parse_number(SATMTMID),
         SATWRMID = readr::parse_number(SATWRMID),
         SAT_AVG = readr::parse_number(SAT_AVG),
         UG = readr::parse_number(UG),
         NPT4_PUB = readr::parse_number(NPT4_PUB),
         NPT4_PRIV = readr::parse_number(NPT4_PRIV),
         COSTT4_A = readr::parse_number(COSTT4_A),
         DEBT_MDN = readr::parse_number(DEBT_MDN),
         CUML_DEBT_P90 = readr::parse_number(CUML_DEBT_P90),
         mn_earn_wne_p10 = readr::parse_number(mn_earn_wne_p10),
         md_earn_wne_p10 = readr::parse_number(md_earn_wne_p10)) %>%
  mutate(RELAFFIL = ifelse(RELAFFIL=="NULL", NA, RELAFFIL),
         LOCALE = ifelse(LOCALE =="NULL", NA, LOCALE),
         CCUGPROF = ifelse(CCUGPROF=="NULL", NA, CCUGPROF),
         HBCU = ifelse(HBCU=="NULL", NA, HBCU),
         WOMENONLY = ifelse(WOMENONLY=="NULL", NA, WOMENONLY)) %>%
  mutate(region2 = ifelse(region=="0", "Military", 
                  ifelse(region=="1", "New England",
                  ifelse(region=="2", "Mid East", 
                  ifelse(region=="3", "Great Lakes",
                  ifelse(region=="4", "Plains", 
                  ifelse(region=="5", "Southeast",
                  ifelse(region=="6", "Southwest", 
                  ifelse(region=="7", "Rocky Mnts",
                  ifelse(region=="8", "Far West", "Outlying"))))))))))

str(college_debt)
summary(college_debt)
```


# Using dynamic data within a typical classroom

Using the downloaded data, we start by applying a technique from the introductory curriculum to a research question of interest based on the College Scorecard data.  College debt is of particular interest to many college students, but debt can be mediated by post-graduation income.  To fully investigate the relationship between the variables, we provide both confidence and prediction intervals for both variables.  

After calculating a few intervals, we show the intervals represented graphically and broken down by geographic region. Note that the visual representations are not a summary plot of the data, and we leave it open to the instructor to have the students engage more deeply with the many available variables.


Using the two variables measuring amount of debt of a typical (i.e., median) college graduate and median earning 10 years after matriculation, we create both confidence intervals and prediction intervals -- keeping in mind that the observational unit is an academic institution.  Note that the calculations below are for both confidence and prediction intervals.  The confidence interval agglomerates institutions over the entire dataset; however, the prediction value is for a single *institution*  (which is the observational unit).  The analysis lends itself nicely to a conversation about confidence vs. prediction intervals as well as observational units as institution vs. as individual student.  It is worth pointing out to the students that the prediction intervals likely hold more information related to their individual experiences than the confidence intervals.  However, the unit of prediction is for an *institution*, and so the individual student debt and income is likely even more variable than shown here. Additionally, Figure \ref{worth} demonstrates the effect of samples size:  consider the comparison of the Military intervals (one school) to the intervals for all of the US institutions (about 6000 schools).  [Note: the intervals given in Figure \ref{worth} were created using an ANOVA model where the within variance is calculated across all regions, which is how the interval for military schools can be calculated.  You may or may not want to bring that up with your students.]


The following R code uses the `mosaic` package to directly calculate both prediction and confidence intervals.  Note the formula interface given by the tilde is described in detail here: http://rpruim.github.io/eCOTS2014/Workshop/Modeling.html.

```{r}
require(mosaic)
debt_mod <- lm(DEBT_MDN~1, data = college_debt)
debt_fun <- mosaic::makeFun(debt_mod)
debt_fun()

debt_fun(interval="confidence")
debt_fun(interval="prediction")

earn_mod <- lm(md_earn_wne_p10~1, data = college_debt)
earn_fun <- mosaic::makeFun(earn_mod)
earn_fun()

earn_fun(interval="confidence")
earn_fun(interval="prediction")
```


The intervals are interesting, but they might be even more interesting if broken down by region and shown visually.  Note how much smaller the confidence intervals are from the prediction intervals!  The difference indicates lots of variability across institutions and large sample sizes.

```{r}
#creating the models for building confidence and prediction intervals:
debtreg_mod <- lm(DEBT_MDN~as.factor(region), data = college_debt)
debtreg_fun <- makeFun(debtreg_mod)
earnreg_mod <- lm(md_earn_wne_p10~as.factor(region), data=college_debt)
earnreg_fun <- makeFun(earnreg_mod)

# creating a dataframe for holding the information needed to plot

worth <- data.frame(fit = double(),
                    lowerbound = double(),
                    upperbound = double(),
                    cost = character(),
                    type = character(),
                    regNum = character(),
                    regName = character(),
                    stringsAsFactors = FALSE)

worth[1,] <- c(debt_fun(interval="conf"), "debt", "conf", "all", "US (all)")
worth[2,] <- c(debt_fun(interval="pred"), "debt", "pred", "all", "US (all)")
worth[3,] <- c(earn_fun(interval="conf"), "earn", "conf", "all", "US (all)")
worth[4,] <- c(earn_fun(interval="pred"), "earn", "pred", "all", "US (all)")

for(i in 0:9){
  worth <- rbind(worth, 
                 c(debtreg_fun(region=i,interval="conf"), "debt","conf",
                   i,college_debt[college_debt$region==i,]$region2[1]))
  worth <- rbind(worth, 
                 c(debtreg_fun(region=i,interval="pred"), "debt","pred",
                   i,college_debt[college_debt$region==i,]$region2[1]))

  worth <- rbind(worth, 
                 c(earnreg_fun(region=i,interval="conf"), "earn","conf",
                   i,college_debt[college_debt$region==i,]$region2[1]))
  worth <- rbind(worth, 
                 c(earnreg_fun(region=i,interval="pred"), "earn","pred",
                   i,college_debt[college_debt$region==i,]$region2[1]))
  }

worth <- worth %>% mutate(fit = readr::parse_number(fit),
                          lowerbound = readr::parse_number(lowerbound),
                          upperbound = readr::parse_number(upperbound))
```

```{r  fig.cap="\\label{worth}The x-axis represents the region of the institution.  The y-axis represents either the amount of debt 10 years after matriculation (orange) or the amount of income 10 years after matriculation (blue).  Confidence intervals for the average values (within region) are given by the solid lines.  Prediction intervals for individual institutions are given by the dashed lines.  The solid dot represents the center of both types of intervals (broken down by debt and income)."}
pd <- position_dodge(width = 1)
ggplot(worth, aes(x=regName, y=fit)) + 
  geom_point(aes(col=cost), position=pd, size=.8) +
  geom_errorbar(aes(ymin=lowerbound, ymax=upperbound, col=cost,
                    lty=type), position=pd) + 
  xlab("Region") + ylab("$debt (orange) or $income (blue) 10 years post matriculation") +
  theme(text = element_text(size=8))
```

# Thinking outside the box


The College Scorecard dataset is incredibly rich and can be used for many different types of model building: linear, logistic, machine learning.  Indeed, thinking about interaction terms could be particularly insightful. Here, we give an example of regressing earnings on debt with the interaction term as whether or not the institution is one of the Historically Black Colleges and Universities (HBCU). Figure \ref{hbcu} displays the separate regression lines for the two distinct types of institutions.


```{r echo=FALSE}
# A great function for helping to write the text of the equation 
# direction onto the plot.  Taken from: http://stackoverflow.com/questions/31014700/plot-two-regression-equations-or-more-on-the-same-graph-ggplot
equation = function(file) {
  mod = lm(md_earn_wne_p10 ~ DEBT_MDN,data=file)
  mod_sum = summary(mod)
  formula = sprintf("Earn= %.3f %+.3f*Debt", coef(mod)[1], coef(mod)[2])
  r = mod_sum$r.squared
  r2 = sprintf("r2= %.3f", r)
  x  = cor.test(~DEBT_MDN + md_earn_wne_p10,data=file)
  r0 = sprintf("r= %.3f", x[4])
  p1 = pf(mod_sum$fstatistic[1],mod_sum$fstatistic[2],mod_sum$fstatistic[3],lower.tail=F)
 p =sprintf("p = %.3f", p1)
n0 = length(mod_sum$residual)
n1 = sprintf("N = %.f", n0)
data.frame(formula=formula, r2=r2, p=p,n=n1, stringsAsFactors=FALSE)
}
```

```{r}
college_debt_nona <- college_debt %>% 
  dplyr::select(md_earn_wne_p10, DEBT_MDN, HBCU) 
college_debt_nona <- college_debt_nona[complete.cases(college_debt_nona),]

earn_lm <- lm(md_earn_wne_p10 ~ DEBT_MDN*HBCU, data=college_debt_nona)
summary(earn_lm)
```

```{r echo=FALSE}
equation_end = plyr::ddply(college_debt_nona, c("HBCU"), equation) 
```

```{r fig.cap="\\label{hbcu}Median income regressed on debt.  For the analysis, HBCU is interacted with debt to provide two distinct (and not parallel) regression lines.  HBCU institutions are given in blue, and non-HBCU institutions are given in orange."}
ggplot(college_debt_nona, aes(x=DEBT_MDN, y=md_earn_wne_p10, color=HBCU)) +
  geom_text(aes(DEBT_MDN,md_earn_wne_p10, label=toString(equation_end[1,-1])),
            data=data.frame(DEBT_MDN=25000, md_earn_wne_p10=180000, HBCU="0"))+
  geom_text(aes(DEBT_MDN,md_earn_wne_p10, label=toString(equation_end[2,-1])),
            data=data.frame(DEBT_MDN=25000, md_earn_wne_p10=160000, HBCU="1"))+
  geom_point(alpha=.25, size=.25) + 
  geom_smooth(method="lm", fill=NA, lwd=.5) +
  xlab("Debt at Graduation") + 
  ylab("Median income 10 years post matriculation")+
  theme(text = element_text(size=10))
```

Many interesting conversations can ensue based on the regression of income on debt.  Reminding the students that each observation is an institution is an important starting point.  Additionally, students should be able to volunteer the dangers of using a model like this to suggest causality.  Last, there might be room to discuss an inferential analysis of whether HBCUs are statistically different from non-HBCUs (noting the substantial differences in sample sizes).

It is not hard to come up with additional questions to investigate with the College Scorecard data.  Indeed, because the data relate directly to college students, they should be able to find many ways to engage with the data.  We recommend continued conversations about how the data are valuable to the larger community, but that the information is not always complete (e.g., many variables are collected only on students who fill out financial aid forms) and not causative.

